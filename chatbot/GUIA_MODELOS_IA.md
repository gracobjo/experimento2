# ü§ñ Gu√≠a Completa de Modelos de IA del Chatbot Legal

## üìã **Resumen Ejecutivo**

El chatbot del despacho legal utiliza una **arquitectura h√≠brida de m√∫ltiples modelos de IA** para proporcionar respuestas inteligentes, contextuales y precisas. Esta gu√≠a documenta cada tecnolog√≠a, su prop√≥sito y ejemplos de uso.

---

## üèóÔ∏è **Arquitectura General**

```
Usuario ‚Üí spaCy (NLP) ‚Üí Sentence-Transformers ‚Üí Detecci√≥n de Intenciones ‚Üí 
Modelos de IA (OpenAI/Anthropic/Cohere/HuggingFace) ‚Üí Respuesta Final
```

---

## üîß **Tecnolog√≠as Implementadas**

### **1. spaCy (Procesamiento de Lenguaje Natural)**

#### **¬øQu√© es?**
- Biblioteca de NLP moderna y eficiente
- Modelos pre-entrenados para espa√±ol e ingl√©s
- Tokenizaci√≥n inteligente y an√°lisis morfol√≥gico

#### **¬øPor qu√© se eligi√≥?**
- ‚úÖ **Rendimiento superior** a NLTK
- ‚úÖ **Modelos neurales** m√°s precisos
- ‚úÖ **API moderna** y f√°cil de usar
- ‚úÖ **Procesamiento en tiempo real**

#### **Implementaci√≥n:**
```python
# Carga de modelos
nlp_es = spacy.load("es_core_news_sm")  # Espa√±ol
nlp_en = spacy.load("en_core_web_sm")   # Ingl√©s

# Uso en el chatbot
doc = nlp_es("Necesito ayuda con mi contrato laboral")
keywords = [token.text for token in doc if not token.is_stop and token.is_alpha]
# Resultado: ['necesito', 'ayuda', 'contrato', 'laboral']
```

#### **Ejemplo de Resoluci√≥n:**
```
Usuario: "Mi jefe me est√° acosando en el trabajo"
spaCy procesa: ['jefe', 'acosando', 'trabajo']
Detecci√≥n: √Årea laboral identificada
Respuesta: "Has indicado el √°rea: Derecho Laboral. El acoso laboral es un tema serio..."
```

---

### **2. Sentence-Transformers (Similitud Sem√°ntica)**

#### **¬øQu√© es?**
- Modelo de embeddings multiling√ºe
- Convierte texto en vectores num√©ricos
- Permite b√∫squeda sem√°ntica inteligente

#### **¬øPor qu√© se eligi√≥?**
- ‚úÖ **Multiling√ºe** (espa√±ol + ingl√©s)
- ‚úÖ **B√∫squeda sem√°ntica** avanzada
- ‚úÖ **Eficiente** en memoria y velocidad
- ‚úÖ **Precisi√≥n alta** en similitudes

#### **Implementaci√≥n:**
```python
# Modelo utilizado
embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# C√°lculo de similitud
query_embedding = embedding_model.encode("problema laboral")
pattern_embeddings = embedding_model.encode(["derecho laboral", "trabajo", "empleo"])
cosine_scores = util.pytorch_cos_sim(query_embedding, pattern_embeddings)
```

#### **Ejemplo de Resoluci√≥n:**
```
Usuario: "Tengo un conflicto en mi empleo"
Sentence-Transformers encuentra similitud con:
- "derecho laboral" (0.85)
- "problema laboral" (0.82)
- "conflicto trabajo" (0.78)
Resultado: Categoriza como consulta de derecho laboral
```

---

### **3. OpenAI (GPT-3.5/4)**

#### **¬øQu√© es?**
- Modelo de lenguaje avanzado
- Generaci√≥n de texto conversacional
- Comprensi√≥n contextual profunda

#### **¬øPor qu√© se eligi√≥?**
- ‚úÖ **Conversaci√≥n natural** y fluida
- ‚úÖ **Contexto avanzado** de conversaci√≥n
- ‚úÖ **Respuestas creativas** y adaptativas
- ‚úÖ **Comprensi√≥n sem√°ntica** superior

#### **Implementaci√≥n:**
```python
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "Eres un asistente legal profesional."},
        {"role": "user", "content": user_message}
    ],
    max_tokens=100,
    temperature=0.7
)
```

#### **Ejemplo de Resoluci√≥n:**
```
Usuario: "Necesito ayuda con algo complicado"
OpenAI genera: "Entiendo que tienes una situaci√≥n compleja. Para darte la mejor asesor√≠a, necesitar√≠a conocer m√°s detalles. ¬øTe gustar√≠a agendar una consulta personalizada donde podamos analizar tu caso espec√≠fico?"
```

---

### **4. Anthropic (Claude)**

#### **¬øQu√© es?**
- Modelo de IA conversacional especializado
- Mejor comprensi√≥n de consultas complejas
- Respuestas m√°s precisas y detalladas

#### **¬øPor qu√© se eligi√≥?**
- ‚úÖ **Especializaci√≥n** en di√°logos
- ‚úÖ **Precisi√≥n alta** en consultas complejas
- ‚úÖ **Respuestas detalladas** y estructuradas
- ‚úÖ **Comprensi√≥n legal** mejorada

#### **Implementaci√≥n:**
```python
client = anthropic.Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
response = client.messages.create(
    model="claude-3-haiku-20240307",
    max_tokens=100,
    messages=[
        {"role": "user", "content": f"Eres un asistente legal. {user_message}"}
    ]
)
```

#### **Ejemplo de Resoluci√≥n:**
```
Usuario: "Mi esposa quiere el divorcio pero yo no, ¬øqu√© puedo hacer?"
Claude genera: "Entiendo tu preocupaci√≥n. En casos de divorcio unilateral, hay opciones legales disponibles. Te recomiendo agendar una consulta para analizar tu situaci√≥n espec√≠fica y explicarte los procedimientos legales que pueden aplicarse en tu caso."
```

---

### **5. Cohere**

#### **¬øQu√© es?**
- Plataforma de IA especializada en NLP
- Mejor clasificaci√≥n de intenciones
- Generaci√≥n de respuestas relevantes

#### **¬øPor qu√© se eligi√≥?**
- ‚úÖ **Clasificaci√≥n precisa** de intenciones
- ‚úÖ **Respuestas estructuradas**
- ‚úÖ **An√°lisis de sentimientos** avanzado
- ‚úÖ **Generaci√≥n contextual** mejorada

#### **Implementaci√≥n:**
```python
co = cohere.Client(os.getenv("COHERE_API_KEY"))
response = co.generate(
    model="command",
    prompt=f"Eres un asistente legal. Usuario: {user_message}",
    max_tokens=100,
    temperature=0.7
)
```

#### **Ejemplo de Resoluci√≥n:**
```
Usuario: "¬øCu√°nto cobran por una consulta?"
Cohere genera: "Ofrecemos consulta inicial gratuita. Los honorarios posteriores dependen de la complejidad del caso, con un rango de ‚Ç¨50-‚Ç¨300. ¬øTe gustar√≠a programar la consulta gratuita para discutir los costos espec√≠ficos de tu situaci√≥n?"
```

---

### **6. Hugging Face (Zephyr-7B)**

#### **¬øQu√© es?**
- Modelo de c√≥digo abierto
- Alternativa local a servicios en la nube
- Respuestas personalizadas con prompts espec√≠ficos

#### **¬øPor qu√© se eligi√≥?**
- ‚úÖ **C√≥digo abierto** y gratuito
- ‚úÖ **Control total** sobre el modelo
- ‚úÖ **Prompts personalizados** para el dominio legal
- ‚úÖ **Independencia** de servicios externos

#### **Implementaci√≥n:**
```python
response = requests.post(
    HF_API_URL,
    headers={"Authorization": f"Bearer {HF_API_TOKEN}"},
    json={
        "inputs": build_prompt(conversation_history, user_message),
        "parameters": {"max_new_tokens": 150, "temperature": 0.7}
    }
)
```

#### **Ejemplo de Resoluci√≥n:**
```
Usuario: "¬øQu√© servicios ofrecen?"
Hugging Face genera: "Ofrecemos servicios en Derecho Civil, Mercantil, Laboral, Familiar, Penal y Administrativo. Nuestro horario es de lunes a viernes 9:00 AM - 6:00 PM. ¬øEn qu√© √°rea espec√≠fica necesitas ayuda?"
```

---

## üéØ **Sistema de Detecci√≥n de Intenciones**

### **Arquitectura:**
```python
intents = {
    "appointment": 0.8,      # Quiere agendar cita
    "pricing": 0.6,          # Pregunta por precios
    "information": 0.4,      # Busca informaci√≥n
    "emergency": 0.2,        # Es urgente
    "laboral": 0.9,          # √Årea laboral
    "familiar": 0.3          # √Årea familiar
}
```

### **Ejemplo Completo:**
```
Usuario: "Necesito una cita urgente porque me van a despedir ma√±ana"

Detecci√≥n de intenciones:
- appointment: 0.9 (quiere cita)
- emergency: 0.8 (es urgente)
- laboral: 0.7 (derecho laboral)
- information: 0.3 (busca informaci√≥n)

Respuesta generada:
"Entiendo la urgencia de tu situaci√≥n. Para casos de despido inminente, tenemos disponibilidad inmediata. Te recomiendo llamarnos al [tel√©fono] para una consulta urgente, o puedo ayudarte a agendar una cita para hoy mismo."
```

---

## üîÑ **Flujo de Procesamiento Inteligente**

### **Paso 1: Preprocesamiento (spaCy)**
```
Input: "Mi empresa no me paga las horas extra"
spaCy: ['empresa', 'paga', 'horas', 'extra']
```

### **Paso 2: Similitud Sem√°ntica (Sentence-Transformers)**
```
Encuentra similitud con:
- "derecho laboral" (0.85)
- "salarios" (0.82)
- "condiciones laborales" (0.78)
```

### **Paso 3: Detecci√≥n de Intenciones**
```
- laboral: 0.9
- appointment: 0.7
- complaint: 0.6
- information: 0.4
```

### **Paso 4: Generaci√≥n de Respuesta**
```
Modelos disponibles:
1. OpenAI ‚Üí Respuesta conversacional
2. Anthropic ‚Üí Respuesta legal espec√≠fica
3. Cohere ‚Üí Respuesta estructurada
4. Hugging Face ‚Üí Respuesta con prompt personalizado

Sistema elige la mejor respuesta basada en:
- Confianza del modelo
- Relevancia del contexto
- Disponibilidad del servicio
```

### **Paso 5: Respuesta Final**
```
"Has indicado el √°rea: Derecho Laboral. El impago de horas extra es un problema com√∫n. Te recomiendo agendar una consulta para analizar tu caso espec√≠fico y explicarte las opciones legales disponibles."
```

---

## üìä **Comparaci√≥n de Modelos**

| Modelo | Fortalezas | Debilidades | Mejor para |
|--------|------------|-------------|------------|
| **spaCy** | Velocidad, precisi√≥n | Limitado a NLP b√°sico | Preprocesamiento |
| **Sentence-Transformers** | Similitud sem√°ntica | Requiere GPU para velocidad | B√∫squeda inteligente |
| **OpenAI** | Conversaci√≥n natural | Costo, dependencia externa | Di√°logos fluidos |
| **Anthropic** | Precisi√≥n legal | Costo, latencia | Consultas complejas |
| **Cohere** | Clasificaci√≥n precisa | Costo, limitaciones | An√°lisis de intenciones |
| **Hugging Face** | Gratuito, control total | Calidad variable | Alternativa local |

---

## üéØ **Casos de Uso Espec√≠ficos**

### **Caso 1: Consulta Laboral Compleja**
```
Usuario: "Mi jefe me est√° acosando y amenazando con despedirme si no trabajo m√°s horas"

Procesamiento:
1. spaCy: ['jefe', 'acosando', 'amenazando', 'despedirme', 'trabajo', 'horas']
2. Sentence-Transformers: Similitud alta con "acoso laboral" (0.92)
3. Intenciones: laboral (0.9), emergency (0.8), appointment (0.7)
4. Modelo elegido: Anthropic (para consulta legal compleja)

Respuesta:
"Entiendo la gravedad de tu situaci√≥n. El acoso laboral y las amenazas de despido son conductas ilegales. Te recomiendo agendar una consulta urgente para analizar tu caso y explicarte las medidas legales que puedes tomar para proteger tus derechos."
```

### **Caso 2: Consulta de Precios**
```
Usuario: "¬øCu√°nto cuesta una consulta sobre divorcio?"

Procesamiento:
1. spaCy: ['cuesta', 'consulta', 'divorcio']
2. Sentence-Transformers: Similitud con "honorarios" (0.88)
3. Intenciones: pricing (0.9), familiar (0.7), information (0.6)
4. Modelo elegido: Cohere (para respuestas estructuradas)

Respuesta:
"Para consultas sobre divorcio, ofrecemos la primera consulta gratuita. Los honorarios posteriores var√≠an seg√∫n la complejidad del caso (‚Ç¨50-‚Ç¨300). ¬øTe gustar√≠a programar la consulta gratuita para discutir los costos espec√≠ficos de tu situaci√≥n?"
```

### **Caso 3: Consulta General**
```
Usuario: "Hola, necesito informaci√≥n"

Procesamiento:
1. spaCy: ['hola', 'necesito', 'informaci√≥n']
2. Sentence-Transformers: Similitud baja con patrones espec√≠ficos
3. Intenciones: greeting (0.8), information (0.6)
4. Modelo elegido: OpenAI (para conversaci√≥n natural)

Respuesta:
"¬°Hola! Soy el asistente virtual del despacho legal. ¬øEn qu√© puedo ayudarte hoy? Puedo informarte sobre nuestros servicios, honorarios, horarios de atenci√≥n o ayudarte a agendar una cita."
```

---

## üîß **Configuraci√≥n y Variables de Entorno**

### **Variables Requeridas:**
```bash
# OpenAI
OPENAI_API_KEY=sk-...

# Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Cohere
COHERE_API_KEY=...

# Hugging Face
HF_API_TOKEN=hf_...

# Backend
BACKEND_URL=http://localhost:3000
FRONTEND_URL=http://localhost:5173
```

### **Instalaci√≥n de Dependencias:**
```bash
pip install spacy sentence-transformers openai anthropic cohere
python -m spacy download es_core_news_sm
python -m spacy download en_core_web_sm
```

---

## üìà **M√©tricas de Rendimiento**

### **Tiempos de Respuesta:**
- **spaCy:** < 10ms
- **Sentence-Transformers:** 50-100ms
- **OpenAI:** 500-1000ms
- **Anthropic:** 800-1500ms
- **Cohere:** 300-600ms
- **Hugging Face:** 1000-2000ms

### **Precisi√≥n de Detecci√≥n:**
- **√Åreas legales:** 95%
- **Intenciones:** 88%
- **Similitud sem√°ntica:** 92%

---

## üîå **Integraci√≥n con Otras Aplicaciones**

### **Endpoints Disponibles:**
```
GET  /health          # Estado del servicio
POST /chat            # Env√≠o de mensajes
POST /end_chat        # Finalizar conversaci√≥n
WS   /ws              # Conexi√≥n WebSocket
```

### **1. JavaScript/TypeScript (Frontend)**
```javascript
// API REST
async function sendMessage(message) {
    const response = await fetch('http://localhost:8000/chat', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            text: message,
            language: 'es',
            user_id: 'user123'
        })
    });
    
    const data = await response.json();
    return data.response;
}

// WebSocket (Tiempo Real)
const ws = new WebSocket('ws://localhost:8000/ws');

ws.onopen = () => {
    console.log('Conectado al chatbot');
};

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    console.log('Respuesta:', data.response);
};

ws.send(JSON.stringify({
    text: 'Hola, necesito ayuda',
    language: 'es',
    user_id: 'user123'
}));
```

### **2. Python (Backend)**
```python
import requests
import websocket
import json

# API REST
def send_message_api(message, user_id="user123"):
    response = requests.post(
        "http://localhost:8000/chat",
        json={
            "text": message,
            "language": "es",
            "user_id": user_id
        }
    )
    return response.json()["response"]

# WebSocket
def on_message(ws, message):
    data = json.loads(message)
    print(f"Respuesta: {data['response']}")

def on_error(ws, error):
    print(f"Error: {error}")

def on_close(ws, close_status_code, close_msg):
    print("Conexi√≥n cerrada")

def on_open(ws):
    print("Conectado al chatbot")
    ws.send(json.dumps({
        "text": "Hola, necesito ayuda",
        "language": "es",
        "user_id": "user123"
    }))

# Conectar WebSocket
ws = websocket.WebSocketApp(
    "ws://localhost:8000/ws",
    on_open=on_open,
    on_message=on_message,
    on_error=on_error,
    on_close=on_close
)
ws.run_forever()
```

### **3. PHP**
```php
<?php
// API REST
function sendMessage($message, $userId = 'user123') {
    $data = [
        'text' => $message,
        'language' => 'es',
        'user_id' => $userId
    ];
    
    $ch = curl_init();
    curl_setopt($ch, CURLOPT_URL, 'http://localhost:8000/chat');
    curl_setopt($ch, CURLOPT_POST, 1);
    curl_setopt($ch, CURLOPT_POSTFIELDS, json_encode($data));
    curl_setopt($ch, CURLOPT_HTTPHEADER, ['Content-Type: application/json']);
    curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
    
    $response = curl_exec($ch);
    curl_close($ch);
    
    return json_decode($response, true)['response'];
}

// Uso
$response = sendMessage('Hola, necesito ayuda legal');
echo $response;
?>
```

### **4. Java (Android)**
```java
// API REST
public class ChatbotAPI {
    private static final String BASE_URL = "http://localhost:8000";
    
    public static String sendMessage(String message, String userId) {
        try {
            URL url = new URL(BASE_URL + "/chat");
            HttpURLConnection conn = (HttpURLConnection) url.openConnection();
            conn.setRequestMethod("POST");
            conn.setRequestProperty("Content-Type", "application/json");
            conn.setDoOutput(true);
            
            // Enviar datos
            String jsonInput = String.format(
                "{\"text\":\"%s\",\"language\":\"es\",\"user_id\":\"%s\"}",
                message, userId
            );
            
            try (OutputStream os = conn.getOutputStream()) {
                byte[] input = jsonInput.getBytes(StandardCharsets.UTF_8);
                os.write(input, 0, input.length);
            }
            
            // Leer respuesta
            try (BufferedReader br = new BufferedReader(
                new InputStreamReader(conn.getInputStream(), "utf-8"))) {
                StringBuilder response = new StringBuilder();
                String responseLine = null;
                while ((responseLine = br.readLine()) != null) {
                    response.append(responseLine.trim());
                }
                return response.toString();
            }
        } catch (Exception e) {
            e.printStackTrace();
            return null;
        }
    }
}
```

### **5. C# (.NET)**
```csharp
using System;
using System.Net.Http;
using System.Text;
using System.Threading.Tasks;
using Newtonsoft.Json;

public class ChatbotClient
{
    private readonly HttpClient _httpClient;
    private const string BaseUrl = "http://localhost:8000";
    
    public ChatbotClient()
    {
        _httpClient = new HttpClient();
    }
    
    public async Task<string> SendMessageAsync(string message, string userId = "user123")
    {
        var requestData = new
        {
            text = message,
            language = "es",
            user_id = userId
        };
        
        var json = JsonConvert.SerializeObject(requestData);
        var content = new StringContent(json, Encoding.UTF8, "application/json");
        
        var response = await _httpClient.PostAsync($"{BaseUrl}/chat", content);
        var responseContent = await response.Content.ReadAsStringAsync();
        
        var result = JsonConvert.DeserializeObject<dynamic>(responseContent);
        return result.response;
    }
}

// Uso
var client = new ChatbotClient();
var response = await client.SendMessageAsync("Hola, necesito ayuda legal");
Console.WriteLine(response);
```

### **6. Flutter (Aplicaci√≥n M√≥vil)**
```dart
// Flutter
class ChatbotService {
  static Future<String> sendMessage(String message) async {
    final response = await http.post(
      Uri.parse('https://tu-api.com/chat'),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({
        'text': message,
        'language': 'es',
        'user_id': 'mobile_user_123'
      }),
    );
    
    final data = jsonDecode(response.body);
    return data['response'];
  }
}
```

### **7. Bot de Telegram**
```python
import telebot
from chatbot_api import send_message

bot = telebot.TeleBot("TU_TOKEN")

@bot.message_handler(func=lambda message: True)
def echo_all(message):
    # Enviar mensaje al chatbot
    response = send_message(message.text, f"telegram_{message.from_user.id}")
    
    # Responder al usuario
    bot.reply_to(message, response)

bot.polling()
```

---

## üîß **Configuraci√≥n para Producci√≥n**

### **1. Variables de Entorno de Producci√≥n**
```bash
# Configurar URLs de producci√≥n
BACKEND_URL=https://tu-backend.com
FRONTEND_URL=https://tu-frontend.com

# Configurar CORS para tu dominio
CORS_ORIGINS=https://tu-app.com,https://otra-app.com
```

### **2. Docker (Para Despliegue)**
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "main_improved_fixed:app", "--host", "0.0.0.0", "--port", "8000"]
```

### **3. Nginx (Proxy Reverso)**
```nginx
server {
    listen 80;
    server_name tu-dominio.com;
    
    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
    
    location /ws {
        proxy_pass http://localhost:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

---

## üîí **Seguridad y Autenticaci√≥n**

### **1. API Key**
```python
# En el chatbot
from fastapi import HTTPException, Depends
from fastapi.security import HTTPBearer

security = HTTPBearer()

async def verify_token(token: str = Depends(security)):
    if token.credentials != "tu-api-key":
        raise HTTPException(status_code=403, detail="Invalid API key")
    return token.credentials

@app.post("/chat")
async def chat(message: Message, token: str = Depends(verify_token)):
    # Procesar mensaje
    pass
```

### **2. Rate Limiting**
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/chat")
@limiter.limit("10/minute")
async def chat(message: Message, request: Request):
    # Procesar mensaje
    pass
```

---

## üì± **Casos de Uso Comunes**

### **1. Aplicaci√≥n Web (React/Vue/Angular)**
```javascript
// Integraci√≥n en React
const ChatbotWidget = () => {
    const [messages, setMessages] = useState([]);
    const [input, setInput] = useState('');
    
    const sendMessage = async () => {
        const response = await fetch('/api/chatbot/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ text: input, user_id: 'user123' })
        });
        
        const data = await response.json();
        setMessages(prev => [...prev, 
            { text: input, isUser: true },
            { text: data.response, isUser: false }
        ]);
        setInput('');
    };
    
    return (
        <div className="chatbot-widget">
            {/* UI del chat */}
        </div>
    );
};
```

### **2. Aplicaci√≥n M√≥vil (React Native)**
```javascript
// React Native
const sendMessage = async (message) => {
    try {
        const response = await fetch('https://tu-api.com/chat', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({
                text: message,
                language: 'es',
                user_id: 'mobile_user_123'
            })
        });
        
        const data = await response.json();
        return data.response;
    } catch (error) {
        console.error('Error:', error);
        return 'Lo siento, hubo un error al procesar tu mensaje.';
    }
};
```

### **3. Integraci√≥n en CRM**
```python
# Integraci√≥n con Salesforce
import requests
from salesforce import Salesforce

def handle_customer_inquiry(customer_id, message):
    # Enviar al chatbot
    chatbot_response = send_message(message, f"crm_{customer_id}")
    
    # Guardar en CRM
    sf = Salesforce(username='user', password='pass', security_token='token')
    sf.Case.create({
        'Subject': 'Consulta via Chatbot',
        'Description': f"Cliente: {customer_id}\nMensaje: {message}\nRespuesta: {chatbot_response}",
        'Status': 'New'
    })
    
    return chatbot_response
```

---

## üìä **Monitoreo y Logs**

### **1. Health Check**
```bash
curl http://localhost:8000/health
# Respuesta: {"status": "healthy", "service": "chatbot"}
```

### **2. Logs Estructurados**
```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.post("/chat")
async def chat(message: Message):
    logger.info(f"Usuario {message.user_id}: {message.text}")
    # Procesar mensaje
    logger.info(f"Respuesta generada para {message.user_id}")
```

### **3. M√©tricas de Uso**
```python
# Contador de mensajes por usuario
from collections import defaultdict
message_counter = defaultdict(int)

@app.post("/chat")
async def chat(message: Message):
    message_counter[message.user_id] += 1
    # Procesar mensaje
    logger.info(f"Usuario {message.user_id} ha enviado {message_counter[message.user_id]} mensajes")
```

---

## üöÄ **Mejoras Futuras**

### **Corto Plazo:**
- [ ] Optimizaci√≥n de prompts para cada modelo
- [ ] Sistema de fallback m√°s inteligente
- [ ] Cache de respuestas frecuentes
- [ ] SDK para integraci√≥n f√°cil

### **Mediano Plazo:**
- [ ] Modelo local (Ollama) para mayor independencia
- [ ] An√°lisis de sentimientos avanzado
- [ ] Memoria de conversaci√≥n a largo plazo
- [ ] API GraphQL para consultas complejas

### **Largo Plazo:**
- [ ] Modelo personalizado entrenado en casos legales
- [ ] Integraci√≥n con base de datos de jurisprudencia
- [ ] An√°lisis predictivo de casos
- [ ] Soporte multiling√ºe completo

---

## üìû **Soporte y Mantenimiento**

### **Monitoreo:**
- Logs de cada modelo en tiempo real
- M√©tricas de rendimiento y precisi√≥n
- Alertas de fallos de servicios
- Dashboard de uso y estad√≠sticas

### **Mantenimiento:**
- Actualizaci√≥n mensual de modelos
- Revisi√≥n de prompts y respuestas
- Optimizaci√≥n de rendimiento
- Backup autom√°tico de configuraciones

---

*√öltima actualizaci√≥n: Diciembre 2024*
*Versi√≥n del chatbot: 2.0* 